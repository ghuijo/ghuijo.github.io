<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://ghuijo.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ghuijo.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-09T20:30:11+00:00</updated><id>https://ghuijo.github.io/feed.xml</id><title type="html">blank</title><entry><title type="html">LeRobot Pi0 Finetuning Tutorial</title><link href="https://ghuijo.github.io/blog/2025/LeRobot-PI0-Finetuning-Tutorial/" rel="alternate" type="text/html" title="LeRobot Pi0 Finetuning Tutorial"/><published>2025-08-29T00:00:00+00:00</published><updated>2025-08-29T00:00:00+00:00</updated><id>https://ghuijo.github.io/blog/2025/LeRobot-PI0-Finetuning-Tutorial</id><content type="html" xml:base="https://ghuijo.github.io/blog/2025/LeRobot-PI0-Finetuning-Tutorial/"><![CDATA[<p>This is a blog post on how to finetune LeRobot Pi0 with SO-ARM101.</p> <h3 id="references">References</h3> <p><a href="https://huggingface.co/docs/lerobot/il_robots">LeRobot Imitation Learning Tutorial</a></p> <p><a href="https://huggingface.co/blog/pi0">LeRobot Pi0 and Pi0-fast Blog</a></p> <h3 id="experiment-environment">Experiment environment</h3> <ul> <li>Robot: SO-ARM101</li> <li>GPU: Tesla A100 SXM4 40GB</li> <li>OS: Ubuntu 20.04 LTS</li> <li>NVIDIA Driver: 570.169 (CUDA 12.8)</li> </ul> <h3 id="anaconda-environment-setup">Anaconda environment setup</h3> <ul> <li> <p><strong>Install Python 3.10 or higher</strong></p> </li> <li> <p><strong>Install PyTorch</strong></p> </li> </ul> <p>Currently, LeRobot only supports PyTorch versions below 2.8. Use the following command to install a compatible version:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span><span class="nv">torch</span><span class="o">==</span>2.7.1 <span class="nv">torchvision</span><span class="o">==</span>0.22.1 <span class="nv">torchaudio</span><span class="o">==</span>2.7.1 <span class="nt">--index-url</span> https://download.pytorch.org/whl/cu128
</code></pre></div></div> <ul> <li><strong>Log in to WandB &amp; Hugging Face</strong></li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>wandb login
</code></pre></div></div> <p>(Tip: If your school email can be verified, you can use WandB for free ‚Äî even after graduation.)</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>huggingface-cli login
</code></pre></div></div> <ul> <li><strong>Install Additional Required Libraries</strong></li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>transformers iniconfig pytest
</code></pre></div></div> <ul> <li>Depending on your environment, you might get an error asking you to install ffmpeg. There are several ways to install it, but the following method worked most cleanly:</li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>conda <span class="nb">install</span> <span class="nt">-n</span> pi0 <span class="nt">-c</span> conda-forge <span class="s2">"ffmpeg&gt;=6,&lt;8"</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>üëâ This installs ffmpeg (version ‚â•6 and &lt;8) into the conda environment named pi0.
</code></pre></div></div> <ul> <li><strong>Request Access to the Pretrained Model (PaliGemma)</strong></li> </ul> <p>Get access here: üîó https://huggingface.co/google/paligemma-3b-pt-224</p> <h3 id="pi0-finetuning">Pi0 finetuning</h3> <p>When you install LeRobot, it automatically links the command lerobot-train to train.py. However, you can also run it directly like this. Since the command is quite long, it‚Äôs convenient to save it as a train.sh file and run it using:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sh train.sh
</code></pre></div></div> <ul> <li>Example training command:</li> </ul> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">CUDA_VISIBLE_DEVICES</span><span class="o">=</span>3 python src/lerobot/scripts/train.py <span class="se">\</span>
<span class="nt">--policy</span>.path<span class="o">=</span>lerobot/pi0 <span class="se">\</span>
<span class="nt">--dataset</span>.repo_id<span class="o">={</span>HF_USER<span class="o">}</span>/<span class="o">{</span>data_name<span class="o">}</span> <span class="se">\</span>
<span class="nt">--output_dir</span><span class="o">=</span>outputs/train/<span class="o">{</span>project_name<span class="o">}</span> <span class="se">\</span>
<span class="nt">--job_name</span><span class="o">=</span>pi0_so101_finetune <span class="se">\</span>
<span class="nt">--policy</span>.device<span class="o">=</span>cuda <span class="se">\</span>
<span class="nt">--policy</span>.repo_id<span class="o">=</span>None <span class="se">\</span>
<span class="nt">--task</span><span class="o">=</span><span class="s2">"move doll into a cup"</span> <span class="se">\</span>
<span class="nt">--wandb</span>.enable<span class="o">=</span><span class="nb">true</span> <span class="se">\</span>
<span class="nt">--wandb</span>.project<span class="o">=</span><span class="s2">"{project_name}"</span>
</code></pre></div></div> <ul> <li>Parameter explanations:</li> </ul> <p>policy.path ‚Äì If you‚Äôre using pretrained model weights, specify the Hugging Face repository containing those weights.</p> <p>policy.repo_id ‚Äì If you want to automatically upload your trained model to Hugging Face during training, specify your own repository here.</p> <p>task ‚Äì I didn‚Äôt realize at first, but this is where you input the text prompt that serves as a language command for the model.</p> <p>wandb.enable ‚Äì Set this to true to visualize your training logs as graphs on the WandB dashboard.</p> <ul> <li>config setting:</li> </ul> <p>num_episode: 50</p> <p>batch_size: 8</p> <p>save_steps: 5000 / 10000</p> <p>‚Äúfreeze_vision_encoder‚Äù: true,</p> <p>‚Äútrain_expert_only‚Äù: <strong>false</strong>,</p> <p>‚Äútrain_state_proj‚Äù: true</p> <h3 id="modifying-training-configuration">Modifying Training Configuration</h3> <p>In src/lerobot/configs/train.py, you can adjust parameters such as: num_workers, batch_size, steps, eval_freq, log_freq, and save_freq.</p> <p>In src/lerobot/policies/pi0/configuration_pi0.py, you can modify additional options such as train_expert_only and related settings.</p> <h3 id="uploading-a-trained-model-to-hugging-face-specific-checkpoint">Uploading a Trained Model to Hugging Face (Specific Checkpoint)</h3> <p>To upload a specific checkpoint to Hugging Face, use the following command:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>huggingface-cli upload <span class="o">{</span>HF_USER<span class="o">}</span>/<span class="o">{</span>project_name<span class="o">}</span> outputs/train/<span class="o">{</span>project_name<span class="o">}</span>/checkpoints/<span class="o">{</span>checkpoint_step<span class="o">}</span>/pretrained_model
</code></pre></div></div> <p>There is no need to manually create the repository in advance ‚Äî it will be created automatically as a public repository during upload.</p> <h3 id="inference">Inference</h3> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lerobot-record  <span class="se">\</span>
<span class="nt">--robot</span>.type<span class="o">=</span>so100_follower <span class="se">\</span>
<span class="nt">--robot</span>.port<span class="o">=</span>/dev/ttyACM1 <span class="se">\</span>
<span class="nt">--robot</span>.cameras<span class="o">=</span><span class="s2">"{ up: {type: opencv, index_or_path: /dev/video10, width: 640, height: 480, fps: 30}, side: {type: intelrealsense, serial_number_or_name: 233522074606, width: 640, height: 480, fps: 30}}"</span> <span class="se">\</span>
<span class="nt">--robot</span>.id<span class="o">=</span>my_awesome_follower_arm <span class="se">\</span>
<span class="nt">--display_data</span><span class="o">=</span><span class="nb">false</span> <span class="se">\</span>
<span class="nt">--dataset</span>.repo_id<span class="o">=</span><span class="k">${</span><span class="nv">HF_USER</span><span class="k">}</span>/eval_so100 <span class="se">\</span>
<span class="nt">--dataset</span>.single_task<span class="o">=</span><span class="s2">"Put lego brick into the transparent box"</span> <span class="se">\</span>
<span class="c"># &lt;- Teleop optional if you want to teleoperate in between episodes \</span>
<span class="c"># -teleop.type=so100_leader \</span>
<span class="c"># -teleop.port=/dev/ttyACM0 \</span>
<span class="c"># -teleop.id=my_awesome_leader_arm \</span>
- <span class="nt">-policy</span>.path<span class="o">=</span><span class="k">${</span><span class="nv">HF_USER</span><span class="k">}</span>/my_policy
</code></pre></div></div> <h3 id="some-comments">Some comments</h3> <p>Unlike ACT or Diffusion Policy, which are trained from scratch, I fine-tuned Pi0 and ran inference with it. Even though the training data were collected only in bright indoor environments with the lights on, the robot still managed to perform tasks pretty accurately even in darker settings.</p> <p>From what I‚Äôve seen in GitHub issues and tutorials, Pi0 tends to work best when it‚Äôs heavily overfitted to a small number of tasks ‚Äî kind of the opposite of what you‚Äôd expect from a general foundation model. It seems that even large-scale robot foundation models struggle with the huge diversity in robot hardware, task types, and data collection environments.</p> <p>I‚Äôm really curious to see how GROOT handles this.</p> <p>Feel free to reach out if you run into any problems or have suggestions for improving this setup!</p>]]></content><author><name></name></author><category term="robotics"/><category term="Imitation_leaning,"/><category term="LeRobot,"/><category term="Pi0"/><summary type="html"><![CDATA[This is a blog post on how to finetune LeRobot Pi0 with SO-ARM101.]]></summary></entry></feed>